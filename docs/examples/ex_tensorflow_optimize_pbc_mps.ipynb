{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e79bdd82-de63-4c38-9e86-bdb2fe44aebe",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "(ex-tensorflow-tn-opt)=\n",
    "\n",
    "# Optimizing a Tensor Network using Tensorflow\n",
    "\n",
    "In this example we show how a general machine learning\n",
    "strategy can be used to optimize arbitrary tensor networks\n",
    "with respect to any target loss function.\n",
    "\n",
    "We'll take the example of maximizing the overlap of some\n",
    "matrix product state with periodic boundary conditions\n",
    "with a densely represented state, since this does not\n",
    "have a simple, deterministic alternative.\n",
    "\n",
    "`quimb` makes use of `cotengra` which can contract\n",
    "tensors with a variety of backends as well as `autoray`\n",
    "for handling array operations agnostically. Here we'll use\n",
    "`tensorflow-v2` for the actual auto-gradient computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aab67ab-23e7-48cd-aec3-e43bc22e729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "import quimb as qu\n",
    "import quimb.tensor as qtn\n",
    "from quimb.tensor.optimize import TNOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5698abc8-2fe9-4932-b146-540f378def6b",
   "metadata": {},
   "source": [
    "First, find a (dense) PBC groundstate, $| gs \\rangle$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81ef42eb-f703-4bad-bff1-1b903b5b07f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 16\n",
    "H = qu.ham_heis(L, sparse=True, cyclic=True)\n",
    "gs = qu.groundstate(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea8a9c4-7985-4198-b9c8-97f99af97da7",
   "metadata": {},
   "source": [
    "Then we convert it to a dense 1D 'tensor network':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3998995-e1bc-4bc3-ae29-8e56953a4430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense1D([\n",
      "    Tensor(shape=(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), inds=('k0', 'k1', 'k2', 'k3', 'k4', 'k5', 'k6', 'k7', 'k8', 'k9', 'k10', 'k11', 'k12', 'k13', 'k14', 'k15'), tags=oset(['I0', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10', 'I11', 'I12', 'I13', 'I14', 'I15'])),\n",
      "], tensors=1, indices=16, L=16, max_bond=2)\n"
     ]
    }
   ],
   "source": [
    "# this converts the dense vector to an effective 1D tensor network (with only one tensor)\n",
    "target = qtn.Dense1D(gs)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b42ade-fed5-4afe-9106-ebd3451bfe2f",
   "metadata": {},
   "source": [
    "Next we create an initial guess random MPS, $|\\psi\\rangle$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a2066ed-fc9d-439a-ad67-c0d035403289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?><!DOCTYPE svg  PUBLIC '-//W3C//DTD SVG 1.1//EN'  'http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd'><svg width=\"440.4pt\" height=\"436.72pt\" version=\"1.1\" viewBox=\"0 0 440.4 436.72\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs><style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style></defs><path d=\"m0 436.72h440.4v-436.72h-440.4v436.72z\" opacity=\"0\"/><g fill=\"none\" stroke=\"#737880\" stroke-opacity=\".5\"><path d=\"m89.001 303.93-23.084-56.255\" clip-path=\"url(#fbc9cc73db3)\" stroke-width=\"5\"/><path d=\"m89.001 303.93 43.104 43.058\" clip-path=\"url(#fbc9cc73db3)\" stroke-width=\"5\"/><path d=\"m89.001 303.93-27.59 18.132\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m65.917 247.67 0.56894-60.757\" clip-path=\"url(#fbc9cc73db3)\" stroke-width=\"5\"/><path d=\"m65.917 247.67-32.475 6.1607\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m132.1 346.98 56.354 23.441\" clip-path=\"url(#fbc9cc73db3)\" stroke-width=\"5\"/><path d=\"m132.1 346.98-18.712 27.049\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m188.46 370.42 61.022 0.44689\" clip-path=\"url(#fbc9cc73db3)\" stroke-width=\"5\"/><path d=\"m188.46 370.42-6.6377 32.136\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m249.48 370.87 56.712-22.87\" clip-path=\"url(#fbc9cc73db3)\" stroke-width=\"5\"/><path d=\"m249.48 370.87 6.3292 32.408\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m306.19 348 43.678-42.73\" clip-path=\"url(#fbc9cc73db3)\" stroke-width=\"5\"/><path d=\"m306.19 348 18.18 27.403\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m349.87 305.27 24.019-55.908\" clip-path=\"url(#fbc9cc73db3)\" stroke-width=\"5\"/><path d=\"m349.87 305.27 27.318 18.393\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m373.89 249.36 0.58437-60.849\" clip-path=\"url(#fbc9cc73db3)\" stroke-width=\"5\"/><path d=\"m373.89 249.36 32.385 6.483\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m374.48 188.51-23.028-56.177\" clip-path=\"url(#fbc9cc73db3)\" stroke-width=\"5\"/><path d=\"m374.48 188.51 32.482-6.2137\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m351.45 132.34-43.217-43.091\" clip-path=\"url(#fbc9cc73db3)\" stroke-width=\"5\"/><path d=\"m351.45 132.34 27.587-18.297\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m308.23 89.247-56.271-23.265\" clip-path=\"url(#fbc9cc73db3)\" stroke-width=\"5\"/><path d=\"m308.23 89.247 18.587-27.181\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m251.96 65.982-61.248-0.34334\" clip-path=\"url(#fbc9cc73db3)\" stroke-width=\"5\"/><path d=\"m251.96 65.982 6.8009-32.057\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m190.71 65.639-56.68 22.72\" clip-path=\"url(#fbc9cc73db3)\" stroke-width=\"5\"/><path d=\"m190.71 65.639-6.33-32.197\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m134.03 88.359-43.547 42.592\" clip-path=\"url(#fbc9cc73db3)\" stroke-width=\"5\"/><path d=\"m134.03 88.359-18.407-27.422\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m90.485 130.95-23.999 55.961\" clip-path=\"url(#fbc9cc73db3)\" stroke-width=\"5\"/><path d=\"m90.485 130.95-27.372-18.336\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m66.486 186.91-32.342-6.6729\" clip-path=\"url(#fbc9cc73db3)\"/></g><g fill=\"#737880\" stroke=\"#5c6066\" stroke-width=\"2.3966\"><path d=\"m89.001 309.92c1.5889 0 3.113-0.63129 4.2366-1.7548s1.7548-2.6476 1.7548-4.2366c0-1.5889-0.63129-3.113-1.7548-4.2366s-2.6476-1.7548-4.2366-1.7548c-1.5889 0-3.113 0.63129-4.2366 1.7548s-1.7548 2.6476-1.7548 4.2366c0 1.5889 0.63129 3.113 1.7548 4.2366s2.6476 1.7548 4.2366 1.7548z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m65.917 253.66c1.5889 0 3.113-0.63129 4.2366-1.7548s1.7548-2.6476 1.7548-4.2366-0.63129-3.113-1.7548-4.2366c-1.1235-1.1235-2.6476-1.7548-4.2366-1.7548-1.5889 0-3.113 0.63129-4.2366 1.7548-1.1235 1.1235-1.7548 2.6476-1.7548 4.2366s0.63129 3.113 1.7548 4.2366 2.6476 1.7548 4.2366 1.7548z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m132.1 352.97c1.5889 0 3.113-0.63129 4.2366-1.7548 1.1235-1.1235 1.7548-2.6476 1.7548-4.2366s-0.63129-3.113-1.7548-4.2366c-1.1235-1.1235-2.6476-1.7548-4.2366-1.7548s-3.113 0.63129-4.2366 1.7548-1.7548 2.6476-1.7548 4.2366 0.63129 3.113 1.7548 4.2366 2.6476 1.7548 4.2366 1.7548z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m188.46 376.42c1.5889 0 3.113-0.63129 4.2366-1.7548 1.1235-1.1235 1.7548-2.6476 1.7548-4.2366s-0.63129-3.113-1.7548-4.2366-2.6476-1.7548-4.2366-1.7548-3.113 0.63129-4.2366 1.7548-1.7548 2.6476-1.7548 4.2366 0.63129 3.113 1.7548 4.2366c1.1235 1.1235 2.6476 1.7548 4.2366 1.7548z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m249.48 376.86c1.5889 0 3.113-0.63129 4.2366-1.7548s1.7548-2.6476 1.7548-4.2366-0.63129-3.113-1.7548-4.2366c-1.1235-1.1235-2.6476-1.7548-4.2366-1.7548-1.5889 0-3.113 0.63129-4.2366 1.7548-1.1235 1.1235-1.7548 2.6476-1.7548 4.2366s0.63129 3.113 1.7548 4.2366 2.6476 1.7548 4.2366 1.7548z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m306.19 353.99c1.5889 0 3.113-0.63129 4.2366-1.7548s1.7548-2.6476 1.7548-4.2366c0-1.5889-0.63129-3.113-1.7548-4.2366s-2.6476-1.7548-4.2366-1.7548-3.113 0.63129-4.2366 1.7548c-1.1235 1.1235-1.7548 2.6476-1.7548 4.2366 0 1.5889 0.63129 3.113 1.7548 4.2366 1.1235 1.1235 2.6476 1.7548 4.2366 1.7548z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m349.87 311.26c1.5889 0 3.113-0.63129 4.2366-1.7548 1.1235-1.1235 1.7548-2.6476 1.7548-4.2366s-0.63129-3.113-1.7548-4.2366-2.6476-1.7548-4.2366-1.7548-3.113 0.63129-4.2366 1.7548-1.7548 2.6476-1.7548 4.2366 0.63129 3.113 1.7548 4.2366c1.1235 1.1235 2.6476 1.7548 4.2366 1.7548z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m373.89 255.35c1.5889 0 3.113-0.63129 4.2366-1.7548s1.7548-2.6476 1.7548-4.2366-0.63129-3.113-1.7548-4.2366-2.6476-1.7548-4.2366-1.7548c-1.5889 0-3.113 0.63129-4.2366 1.7548s-1.7548 2.6476-1.7548 4.2366 0.63129 3.113 1.7548 4.2366 2.6476 1.7548 4.2366 1.7548z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m374.48 194.51c1.5889 0 3.113-0.63129 4.2366-1.7548s1.7548-2.6476 1.7548-4.2366c0-1.5889-0.63129-3.113-1.7548-4.2366s-2.6476-1.7548-4.2366-1.7548c-1.5889 0-3.113 0.63129-4.2366 1.7548s-1.7548 2.6476-1.7548 4.2366c0 1.5889 0.63129 3.113 1.7548 4.2366s2.6476 1.7548 4.2366 1.7548z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m351.45 138.33c1.5889 0 3.113-0.63129 4.2366-1.7548s1.7548-2.6476 1.7548-4.2366c0-1.5889-0.63129-3.113-1.7548-4.2366s-2.6476-1.7548-4.2366-1.7548c-1.5889 0-3.113 0.63129-4.2366 1.7548s-1.7548 2.6476-1.7548 4.2366c0 1.5889 0.63129 3.113 1.7548 4.2366s2.6476 1.7548 4.2366 1.7548z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m308.23 95.238c1.5889 0 3.113-0.63129 4.2366-1.7548s1.7548-2.6476 1.7548-4.2366c0-1.5889-0.63129-3.113-1.7548-4.2366s-2.6476-1.7548-4.2366-1.7548c-1.5889 0-3.113 0.63129-4.2366 1.7548s-1.7548 2.6476-1.7548 4.2366c0 1.5889 0.63129 3.113 1.7548 4.2366s2.6476 1.7548 4.2366 1.7548z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m251.96 71.974c1.5889 0 3.113-0.63129 4.2366-1.7548s1.7548-2.6476 1.7548-4.2366c0-1.5889-0.63129-3.113-1.7548-4.2366s-2.6476-1.7548-4.2366-1.7548c-1.5889 0-3.113 0.63129-4.2366 1.7548s-1.7548 2.6476-1.7548 4.2366c0 1.5889 0.63129 3.113 1.7548 4.2366s2.6476 1.7548 4.2366 1.7548z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m190.71 71.63c1.5889 0 3.113-0.63129 4.2366-1.7548s1.7548-2.6476 1.7548-4.2366-0.63129-3.113-1.7548-4.2366-2.6476-1.7548-4.2366-1.7548c-1.5889 0-3.113 0.63129-4.2366 1.7548s-1.7548 2.6476-1.7548 4.2366 0.63129 3.113 1.7548 4.2366 2.6476 1.7548 4.2366 1.7548z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m134.03 94.351c1.5889 0 3.113-0.63129 4.2366-1.7548 1.1235-1.1235 1.7548-2.6476 1.7548-4.2366s-0.63129-3.113-1.7548-4.2366c-1.1235-1.1235-2.6476-1.7548-4.2366-1.7548s-3.113 0.63129-4.2366 1.7548c-1.1235 1.1235-1.7548 2.6476-1.7548 4.2366s0.63129 3.113 1.7548 4.2366 2.6476 1.7548 4.2366 1.7548z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m90.485 136.94c1.5889 0 3.113-0.63129 4.2366-1.7548s1.7548-2.6476 1.7548-4.2366-0.63129-3.113-1.7548-4.2366c-1.1235-1.1235-2.6476-1.7548-4.2366-1.7548s-3.113 0.63129-4.2366 1.7548c-1.1235 1.1235-1.7548 2.6476-1.7548 4.2366s0.63129 3.113 1.7548 4.2366 2.6476 1.7548 4.2366 1.7548z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m66.486 192.9c1.5889 0 3.113-0.63129 4.2366-1.7548s1.7548-2.6476 1.7548-4.2366-0.63129-3.113-1.7548-4.2366c-1.1235-1.1235-2.6476-1.7548-4.2366-1.7548-1.5889 0-3.113 0.63129-4.2366 1.7548-1.1235 1.1235-1.7548 2.6476-1.7548 4.2366s0.63129 3.113 1.7548 4.2366 2.6476 1.7548 4.2366 1.7548z\" clip-path=\"url(#fbc9cc73db3)\"/></g><g fill=\"#ffffff\"><path d=\"m61.41 322.06z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m113.39 374.03z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m181.82 402.56z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m255.81 403.28z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m324.37 375.4z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m377.19 323.66z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m406.28 255.85z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m406.96 182.3z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m379.03 114.04z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m326.82 62.066z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m258.76 33.925z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m184.38 33.442z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m115.62 60.937z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m63.112 112.62z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m34.144 180.24z\" clip-path=\"url(#fbc9cc73db3)\"/><path d=\"m33.442 253.83z\" clip-path=\"url(#fbc9cc73db3)\"/></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(82.98 306.71) scale(.1 -.1)\" fill=\"#404040\"><defs><path id=\"DejaVuSansMono-49\" transform=\"scale(.015625)\" d=\"m628 4666h2591v-532h-978v-3603h978v-531h-2591v531h978v3603h-978v532z\"/><path id=\"DejaVuSansMono-30\" transform=\"scale(.015625)\" d=\"m1509 2344q0 172 120 297 121 125 290 125 175 0 300-125t125-297q0-175-124-297-123-122-301-122-175 0-293 119-117 119-117 300zm416 1906q-441 0-658-475t-217-1447q0-969 217-1444t658-475q444 0 661 475t217 1444q0 972-217 1447t-661 475zm0 500q747 0 1130-613 383-612 383-1809 0-1194-383-1807-383-612-1130-612t-1128 612q-381 613-381 1807 0 1197 381 1809 381 613 1128 613z\"/></defs><use xlink:href=\"#DejaVuSansMono-49\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-30\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(56.886 250.46) scale(.1 -.1)\" fill=\"#404040\"><defs><path id=\"DejaVuSansMono-31\" transform=\"scale(.015625)\" d=\"m844 531h981v3566l-1056-238v575l1050 232h631v-4135h969v-531h-2575v531z\"/><path id=\"DejaVuSansMono-35\" transform=\"scale(.015625)\" d=\"m647 4666h2362v-532h-1787v-1146q134 50 270 73t274 23q725 0 1150-428t425-1159q0-738-446-1163-445-425-1217-425-372 0-680 50-307 50-551 150v641q287-156 578-233 291-76 594-76 522 0 804 275 283 275 283 781 0 500-292 778t-814 278q-253 0-494-58-240-57-459-173v2344z\"/></defs><use xlink:href=\"#DejaVuSansMono-49\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-31\"/><use x=\"120.410156\" xlink:href=\"#DejaVuSansMono-35\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(126.08 349.77) scale(.1 -.1)\" fill=\"#404040\"><use xlink:href=\"#DejaVuSansMono-49\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-31\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(55.39 324.84) scale(.1 -.1)\" fill=\"#404040\"><defs><path id=\"DejaVuSansMono-6b\" transform=\"scale(.015625)\" d=\"m738 4863h593v-2816l1510 1453h700l-1378-1319 1593-2181h-703l-1294 1806-428-403v-1403h-593v4863z\"/></defs><use xlink:href=\"#DejaVuSansMono-6b\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-30\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(182.44 373.21) scale(.1 -.1)\" fill=\"#404040\"><defs><path id=\"DejaVuSansMono-32\" transform=\"scale(.015625)\" d=\"m1166 531h2143v-531h-2834v531q584 616 1021 1088 438 472 604 665 313 382 422 618t109 482q0 391-230 613-229 222-629 222-284 0-597-103-312-103-662-313v638q321 153 632 231t614 78q685 0 1102-364t417-955q0-300-139-600t-451-662q-175-203-508-563-333-359-1014-1075z\"/></defs><use xlink:href=\"#DejaVuSansMono-49\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-32\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(107.37 376.82) scale(.1 -.1)\" fill=\"#404040\"><use xlink:href=\"#DejaVuSansMono-6b\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-31\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(243.46 373.66) scale(.1 -.1)\" fill=\"#404040\"><defs><path id=\"DejaVuSansMono-33\" transform=\"scale(.015625)\" d=\"m2425 2497q459-122 703-433t244-776q0-644-433-1012-433-367-1198-367-322 0-657 60-334 59-656 172v628q319-166 628-247 310-81 616-81 519 0 797 234t278 675q0 406-278 645t-753 239h-482v519h482q434 0 678 190 244 191 244 532 0 359-227 551-227 193-645 193-278 0-575-63-297-62-622-187v581q378 100 673 150 296 50 524 50 681 0 1089-342t408-908q0-384-215-641-214-256-623-362z\"/></defs><use xlink:href=\"#DejaVuSansMono-49\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-33\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(175.8 405.35) scale(.1 -.1)\" fill=\"#404040\"><use xlink:href=\"#DejaVuSansMono-6b\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-32\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(300.17 350.79) scale(.1 -.1)\" fill=\"#404040\"><defs><path id=\"DejaVuSansMono-34\" transform=\"scale(.015625)\" d=\"m2297 4091-1472-2466h1472v2466zm-103 575h731v-3041h622v-512h-622v-1113h-628v1113h-1978v596l1875 2957z\"/></defs><use xlink:href=\"#DejaVuSansMono-49\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-34\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(249.79 406.07) scale(.1 -.1)\" fill=\"#404040\"><use xlink:href=\"#DejaVuSansMono-6b\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-33\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(343.85 308.06) scale(.1 -.1)\" fill=\"#404040\"><use xlink:href=\"#DejaVuSansMono-49\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-35\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(318.35 378.19) scale(.1 -.1)\" fill=\"#404040\"><use xlink:href=\"#DejaVuSansMono-6b\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-34\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(367.87 252.15) scale(.1 -.1)\" fill=\"#404040\"><defs><path id=\"DejaVuSansMono-36\" transform=\"scale(.015625)\" d=\"m3097 4563v-582q-197 116-419 177t-462 61q-600 0-910-452-309-451-309-1329 150 312 415 479 266 167 610 167 675 0 1045-414 371-414 371-1173 0-756-382-1172-381-416-1072-416-812 0-1190 583t-378 1836q0 1181 454 1801 455 621 1318 621 231 0 462-49 231-48 447-138zm-1125-1972q-403 0-635-291-231-291-231-803 0-513 231-804 232-290 635-290 419 0 631 276 213 277 213 818 0 544-213 819-212 275-631 275z\"/></defs><use xlink:href=\"#DejaVuSansMono-49\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-36\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(371.17 326.45) scale(.1 -.1)\" fill=\"#404040\"><use xlink:href=\"#DejaVuSansMono-6b\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-35\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(368.45 191.3) scale(.1 -.1)\" fill=\"#404040\"><defs><path id=\"DejaVuSansMono-37\" transform=\"scale(.015625)\" d=\"m434 4666h2938v-269l-1669-4397h-659l1625 4134h-2235v532z\"/></defs><use xlink:href=\"#DejaVuSansMono-49\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-37\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(400.26 258.63) scale(.1 -.1)\" fill=\"#404040\"><use xlink:href=\"#DejaVuSansMono-6b\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-36\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(345.43 135.12) scale(.1 -.1)\" fill=\"#404040\"><defs><path id=\"DejaVuSansMono-38\" transform=\"scale(.015625)\" d=\"m1925 2216q-422 0-652-236-229-236-229-667 0-432 232-671 233-239 649-239 425 0 654 236 230 236 230 674 0 428-233 665-232 238-651 238zm-550 262q-403 103-630 384-226 282-226 679 0 556 378 882 378 327 1028 327 653 0 1031-327 378-326 378-882 0-397-227-679-226-281-629-384 469-103 717-416 249-312 249-809 0-631-403-988-403-356-1116-356-712 0-1114 355t-402 983q0 500 248 814 249 314 718 417zm-228 1003q0-375 200-572 200-196 578-196 381 0 581 196 200 197 200 572 0 382-199 582-198 200-582 200-378 0-578-202t-200-580z\"/></defs><use xlink:href=\"#DejaVuSansMono-49\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-38\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(400.94 185.09) scale(.1 -.1)\" fill=\"#404040\"><use xlink:href=\"#DejaVuSansMono-6b\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-37\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(302.21 92.033) scale(.1 -.1)\" fill=\"#404040\"><defs><path id=\"DejaVuSansMono-39\" transform=\"scale(.015625)\" d=\"m1863 2069q403 0 632 290 230 291 230 804 0 512-230 802-229 291-632 291-419 0-632-277-212-276-212-816 0-544 211-819t633-275zm-1125-1972v581q196-115 418-176t463-61q600 0 907 451 308 452 308 1330-146-313-412-480t-609-167q-675 0-1046 415-370 416-370 1179 0 753 379 1167 380 414 1074 414 813 0 1191-585 378-584 378-1837 0-1178-455-1799-455-620-1320-620-228 0-460 49-231 48-446 139z\"/></defs><use xlink:href=\"#DejaVuSansMono-49\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-39\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(373.01 116.83) scale(.1 -.1)\" fill=\"#404040\"><use xlink:href=\"#DejaVuSansMono-6b\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-38\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(242.93 68.768) scale(.1 -.1)\" fill=\"#404040\"><use xlink:href=\"#DejaVuSansMono-49\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-31\"/><use x=\"120.410156\" xlink:href=\"#DejaVuSansMono-30\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(320.8 64.852) scale(.1 -.1)\" fill=\"#404040\"><use xlink:href=\"#DejaVuSansMono-6b\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-39\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(181.68 68.425) scale(.1 -.1)\" fill=\"#404040\"><use xlink:href=\"#DejaVuSansMono-49\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-31\"/><use x=\"120.410156\" xlink:href=\"#DejaVuSansMono-31\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(249.73 36.711) scale(.1 -.1)\" fill=\"#404040\"><use xlink:href=\"#DejaVuSansMono-6b\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-31\"/><use x=\"120.410156\" xlink:href=\"#DejaVuSansMono-30\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(125 91.145) scale(.1 -.1)\" fill=\"#404040\"><use xlink:href=\"#DejaVuSansMono-49\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-31\"/><use x=\"120.410156\" xlink:href=\"#DejaVuSansMono-32\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(175.35 36.228) scale(.1 -.1)\" fill=\"#404040\"><use xlink:href=\"#DejaVuSansMono-6b\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-31\"/><use x=\"120.410156\" xlink:href=\"#DejaVuSansMono-31\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(81.454 133.74) scale(.1 -.1)\" fill=\"#404040\"><use xlink:href=\"#DejaVuSansMono-49\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-31\"/><use x=\"120.410156\" xlink:href=\"#DejaVuSansMono-33\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(106.59 63.723) scale(.1 -.1)\" fill=\"#404040\"><use xlink:href=\"#DejaVuSansMono-6b\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-31\"/><use x=\"120.410156\" xlink:href=\"#DejaVuSansMono-32\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(57.455 189.7) scale(.1 -.1)\" fill=\"#404040\"><use xlink:href=\"#DejaVuSansMono-49\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-31\"/><use x=\"120.410156\" xlink:href=\"#DejaVuSansMono-34\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(54.082 115.4) scale(.1 -.1)\" fill=\"#404040\"><use xlink:href=\"#DejaVuSansMono-6b\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-31\"/><use x=\"120.410156\" xlink:href=\"#DejaVuSansMono-33\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(25.113 183.03) scale(.1 -.1)\" fill=\"#404040\"><use xlink:href=\"#DejaVuSansMono-6b\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-31\"/><use x=\"120.410156\" xlink:href=\"#DejaVuSansMono-34\"/></g></g><g clip-path=\"url(#fbc9cc73db3)\"><g transform=\"translate(24.411 256.62) scale(.1 -.1)\" fill=\"#404040\"><use xlink:href=\"#DejaVuSansMono-6b\"/><use x=\"60.205078\" xlink:href=\"#DejaVuSansMono-31\"/><use x=\"120.410156\" xlink:href=\"#DejaVuSansMono-35\"/></g></g><defs><clipPath id=\"fbc9cc73db3\"><rect x=\"7.2\" y=\"7.2\" width=\"426\" height=\"422.32\"/></clipPath></defs></svg>"
      ],
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bond_dim = 32\n",
    "mps = qtn.MPS_rand_state(L, bond_dim, cyclic=True)\n",
    "mps.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36b2f4e-1b41-4dd0-8632-d41c6f436c10",
   "metadata": {},
   "source": [
    "We now need to set-up the function that 'prepares' our tensor network.\n",
    "In the current example this involves making sure the state is always normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db149116-03bb-480b-9bcd-a571cdaa9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_state(psi):\n",
    "    return psi / (psi.H @ psi) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e1d32f-1e7d-4d71-b705-0eee8fdff13a",
   "metadata": {},
   "source": [
    "Then we need to set-up our 'loss' function, the function that returns\n",
    "the scalar quantity we want to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2423d7b-a539-4031-8849-39955310e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_overlap(psi, target):\n",
    "    return -((psi.H @ target) ** 2)  # minus so as to minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced2ba46-0588-48c5-94f2-1a2d5ed4b436",
   "metadata": {},
   "source": [
    "Now we can set up the tensor network optimizer object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b65588f-526d-4c5f-b88e-054caf62809b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-13 15:16:10.049837: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-13 15:16:10.851994: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-10-13 15:16:11.991099: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-13 15:16:12.047657: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "optmzr = TNOptimizer(\n",
    "    mps,  # our initial input, the tensors of which to optimize\n",
    "    loss_fn=negative_overlap,\n",
    "    norm_fn=normalize_state,\n",
    "    loss_constants={\n",
    "        \"target\": target\n",
    "    },  # this is a constant TN to supply to loss_fn\n",
    "    autodiff_backend=\"tensorflow\",  # {'jax', 'tensorflow', 'autograd'}\n",
    "    optimizer=\"L-BFGS-B\",  # supplied to scipy.minimize\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcc45cb-a269-422f-801a-1c005dbaab7d",
   "metadata": {},
   "source": [
    "Then we are ready to optimize our tensor network! Note how we supplied the constant tensor network ``target`` - its tensors will not be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7ec1ca7-3de4-4ff3-a500-f30d6a937a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-0.999723964428 [best: -0.999723964428] : : 109it [00:19,  5.48it/s]                       \n"
     ]
    }
   ],
   "source": [
    "mps_opt = optmzr.optimize(100)  # perform ~100 gradient descent steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a3b072-608d-4caf-95b5-d376fa1c18bf",
   "metadata": {},
   "source": [
    "The output optimized (and normalized) tensor netwwork has already been converted back to numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d27be2aa-d15b-44a6-8e44-68cdc6dd1dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'numpy'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mps_opt[0].backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033793ca-9e87-4ca2-bdf5-0a53e3d0330a",
   "metadata": {},
   "source": [
    "And we can explicitly check the returned state indeed matches the loss shown above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5756787-b71a-4d9f-bbb6-692dac234f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997239644280398"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((mps_opt.H & target) ^ all) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9cc2a2-0592-48b3-91cf-05878137e8de",
   "metadata": {},
   "source": [
    "Other things to think about might be:\n",
    "\n",
    "- try other scipy optimizers for the `optimizer=` option\n",
    "- try other autodiff backends for the `autodiff_backend=` option\n",
    "    * ``'jax'`` - likely the best performance but slow to compile the initial computation\n",
    "    * ``'autograd'`` - numpy based, cpu-only optimization\n",
    "    * ``'torch'`` - (pytorch), quick compilation and decent performance, though no complex support (yet?)\n",
    "- using single precision data for better GPU acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989cb60d-5393-4f20-a8b5-65353000067d",
   "metadata": {},
   "source": [
    "We can also keep optimizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cf2699c-5d3b-4625-8a2f-583de62f078b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-0.999923989141 [best: -0.999923989141] : : 108it [00:20,  5.30it/s]                       \n"
     ]
    }
   ],
   "source": [
    "mps_opt = optmzr.optimize(100)  # perform another ~100 gradient descent steps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
