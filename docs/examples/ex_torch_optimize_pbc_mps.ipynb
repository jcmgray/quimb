{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing a Tensor Network using Pytorch\n",
    "\n",
    "\n",
    "In this example we show how a general machine learning\n",
    "strategy can be used to optimize tensor networks with\n",
    "respect to some target loss function.\n",
    "\n",
    "We'll take the example of maximizing the overlap of some\n",
    "matrix product state with periodic boundary conditions\n",
    "with a densely represented state, since this does not\n",
    "have a simple, deterministic alternative.\n",
    "\n",
    "``quimb`` makes use of ``opt_einsum`` which can contract\n",
    "tensors with a variety of backends. Here we'll use \n",
    "``pytorch``. Note that pytorch does not yet support complex\n",
    "data (but that also means we don't need to conjugate using\n",
    "the ``.H`` attribute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import quimb as qu\n",
    "import quimb.tensor as qtn\n",
    "\n",
    "# perform all contractions with pytorch\n",
    "qtn.set_contract_backend('torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, find a (dense) PBC groundstate, $| gs \\rangle$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 16\n",
    "H = qu.ham_heis(L, sparse=True, cyclic=True)\n",
    "gs = qu.groundstate(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we convert it to a (constant) torch array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this converts the dense vector to an effective 1D tensor network\n",
    "target = qtn.Dense1D(gs)\n",
    "\n",
    "# this maps the torch.tensor function over all the data arrays, here only one\n",
    "target.apply_to_arrays(torch.tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create an initial guess random MPS, $|\\psi\\rangle$, also converting each \n",
    "of the arrays to torch variables (but now requiring the \n",
    "gradient so that each can be optimized):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_dim = 32\n",
    "mps = qtn.MPS_rand_state(L, bond_dim, cyclic=True)\n",
    "mps.apply_to_arrays(lambda t: torch.tensor(t, requires_grad=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, we set up a ``pytorch`` optimizer, taking as the loss \n",
    "the normalized target overlap $\\dfrac{|\\langle gs | \\psi \\rangle|^2} { \\langle \\psi | \\psi \\rangle }$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round: 10, loss: -0.9405585461294388\n",
      "round: 20, loss: -0.9788279069737648\n",
      "round: 30, loss: -0.9925598607587998\n",
      "round: 40, loss: -0.9965893422669746\n",
      "round: 50, loss: -0.997983439965575\n",
      "round: 60, loss: -0.9986126769786011\n",
      "round: 70, loss: -0.9989872559043187\n",
      "round: 80, loss: -0.9991876671618736\n",
      "round: 90, loss: -0.9993254027902169\n",
      "round: 100, loss: -0.9994244319138171\n"
     ]
    }
   ],
   "source": [
    "# we give the optimizer all the tensors it should optimize\n",
    "optimizer = torch.optim.Adam([t.data for t in mps], lr=0.01)\n",
    "\n",
    "# perform 100 steps of optimization\n",
    "for t in range(1, 101):\n",
    "    \n",
    "    # negate the overlap as we a minimizing\n",
    "    loss = - (mps @ target)**2 / (mps @ mps)\n",
    "    \n",
    "    # reset, compute the gradient, and take a optimize step\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if t % 10 == 0:\n",
    "        print(f\"round: {t}, loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a pretty good fidelity between our PBC MPS ansatz and the target groundstate.\n",
    "\n",
    "Although the loss was computed with normalization, the MPS still needs to be normalized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, dtype=torch.float64, grad_fn=<AsStridedBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mps /= (mps @ mps)**0.5\n",
    "mps @ mps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we can check that the overlap matches the loss found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9994, dtype=torch.float64, grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mps @ target)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other things to think about might be:\n",
    "\n",
    "- playing with the optimizer type (here ADAM) and settings (e.g. learning rate)\n",
    "- using single precision data for GPU acceleration\n",
    "\n",
    "We can also convert the ``pytorch`` arrays back to numpy with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 'detach' unlinks the tensors from the gradient calculator\n",
    "mps.apply_to_arrays(lambda t: t.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mps[4].data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
